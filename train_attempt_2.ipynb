{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "Using device: cuda\n",
      "Libraries imported successfully!\n",
      "PyTorch version: 2.5.1\n",
      "Pandas version: 2.2.3\n",
      "Numpy version: 1.26.4\n",
      "Sklearn version: 1.26.4\n",
      "Matplotlib version: 1.26.4\n",
      "scipy version: 1.26.4\n",
      "tqdm version: 1.26.4\n",
      "pickle version: 1.26.4\n",
      "pathlib version: 1.26.4\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc, precision_recall_curve, roc_auc_score\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from scipy.spatial.distance import squareform\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "\n",
    "print('Libraries imported successfully!')\n",
    "print(f'Using device: {torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")}')\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print('Libraries imported successfully!')\n",
    "print(f'PyTorch version: {torch.__version__}')\n",
    "print(f'Pandas version: {pd.__version__}')\n",
    "print(f'Numpy version: {np.__version__}')\n",
    "print(f'Sklearn version: {np.__version__}')\n",
    "print(f'Matplotlib version: {np.__version__}')\n",
    "print(f'scipy version: {np.__version__}')\n",
    "print(f'tqdm version: {np.__version__}')\n",
    "print(f'pickle version: {np.__version__}')\n",
    "print(f'pathlib version: {np.__version__}')\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {DEVICE}')\n",
    "\n",
    "############################\n",
    "# Other Parameters\n",
    "############################\n",
    "MODEL_DIR = Path('model_weights_2')\n",
    "info_path = MODEL_DIR / 'training_info.pkl'\n",
    "csv_path = MODEL_DIR / 'test_results.csv'\n",
    "txt_path = MODEL_DIR / 'test_results.txt'\n",
    "png_path = MODEL_DIR / 'result.png'\n",
    "\n",
    "distribution_png_path = MODEL_DIR / 'anomaly_score_distribution.png'\n",
    "boxplot_png_path = MODEL_DIR / 'anomaly_score_boxplot.png'\n",
    "precision_recall_png_path = MODEL_DIR / 'precision_recall_curve.png'\n",
    "roc_curve_png_path = MODEL_DIR / 'roc_curve.png'\n",
    "latent_pca_png_path = MODEL_DIR / 'latent_pca_plot.png'\n",
    "\n",
    "WORKER_NODES = 20\n",
    "ANOMALY_THRESHOLD = 0.5\n",
    "MAX_GROUP_SIZE = 16\n",
    "\n",
    "\n",
    "############################\n",
    "# Hyperparameters\n",
    "############################\n",
    "FIRST_LAYER_HIDDEN_SIZE = 16\n",
    "SECOND_LAYER_HIDDEN_SIZE = 128\n",
    "LATENT_DIM_FIRST_LAYER = 16\n",
    "LATENT_DIM_SECOND_LAYER = 32\n",
    "CLUSTER_THRESHOLD = 0.6\n",
    "BATCH_SIZE = 1024\n",
    "EPOCHS_FIRST_LAYER = 3\n",
    "EPOCHS_SECOND_LAYER = 8\n",
    "LEARNING_RATE = 1e-4\n",
    "MAX_GRAD_NORM = 5.0\n",
    "CLAMP_LOGVAR_LOW = -10\n",
    "CLAMP_LOGVAR_HIGH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "# Dataset Definitions\n",
    "############################\n",
    "class FirstLayerDataset(Dataset):\n",
    "    def __init__(self, data, features):\n",
    "        self.X = data[:, features]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx].astype(np.float32)\n",
    "\n",
    "class SecondLayerDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        print(\"Initializing SecondLayerDataset...\")\n",
    "        if isinstance(data, np.ndarray):\n",
    "            self.data = torch.from_numpy(data).float()\n",
    "        elif isinstance(data, torch.Tensor):\n",
    "            self.data = data.float()\n",
    "        else:\n",
    "            raise TypeError(\"Data should be a numpy array or a torch.Tensor.\")\n",
    "        print(f\"Dataset initialized with {len(self)} samples.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= len(self):\n",
    "            raise IndexError(\"Index out of range.\")\n",
    "        return self.data[idx]\n",
    "\n",
    "############################\n",
    "# VAE Model Definition\n",
    "############################\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc2 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, input_dim)\n",
    "        self.activation = nn.LeakyReLU(0.2)  # Using LeakyReLU\n",
    "\n",
    "        # Initialize weights\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "            elif 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.activation(self.fc1(x))\n",
    "        mu = self.fc_mu(h)\n",
    "        logvar = self.fc_logvar(h)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        logvar = torch.clamp(logvar, CLAMP_LOGVAR_LOW, CLAMP_LOGVAR_HIGH)\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std, logvar\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = self.activation(self.fc2(z))\n",
    "        return self.fc3(h)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z, logvar = self.reparameterize(mu, logvar)\n",
    "        recon_x = self.decode(z)\n",
    "        return recon_x, mu, logvar\n",
    "\n",
    "\n",
    "def vae_loss(recon_x, x, mu, logvar):\n",
    "    recon_loss = nn.functional.mse_loss(recon_x, x, reduction='mean')\n",
    "    logvar = torch.clamp(logvar, CLAMP_LOGVAR_LOW, CLAMP_LOGVAR_HIGH)\n",
    "    kld_loss = -0.5 * torch.mean(1 + logvar - mu.pow(2) - torch.exp(logvar))\n",
    "    return recon_loss + kld_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('ARP_MitM_dataset.csv', header=None).values\n",
    "labels = pd.read_csv('ARP_MitM_labels_Y.csv', header=None).values.flatten()\n",
    "\n",
    "TRAIN_SIZE = 1_000_000\n",
    "train_data = data[:TRAIN_SIZE]\n",
    "train_labels = labels[:TRAIN_SIZE]\n",
    "test_data = data[TRAIN_SIZE:]\n",
    "test_labels = labels[TRAIN_SIZE:]\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on training data and transform both training and test data\n",
    "train_data_scaled = scaler.fit_transform(train_data)\n",
    "test_data_scaled = scaler.transform(test_data)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing correlation matrix...\n",
      "Converting correlation to distance...\n",
      "Condensing distance matrix...\n",
      "Performing hierarchical clustering...\n",
      "Plotting dendrogram...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigning initial clusters with threshold 0.6...\n",
      "Initial number of feature groups: 18\n",
      "Group 0: [66, 69, 72, 75, 78]\n",
      "Group 1: [67, 70, 73, 76, 79]\n",
      "Group 2: [36, 43, 50]\n",
      "Group 3: [56, 63]\n",
      "Group 4: [35, 42, 49]\n",
      "Group 5: [99, 100]\n",
      "Group 6: [106, 107]\n",
      "Group 7: [113, 114]\n",
      "Group 8: [85, 86]\n",
      "Group 9: [92, 93]\n",
      "Group 10: [12, 27, 58, 77, 108]\n",
      "Group 11: [33, 40, 47, 54, 61]\n",
      "Group 12: [57, 64]\n",
      "Group 13: [0, 3, 6, 9, 15, 18, 21, 24, 30, 34, 37, 41, 44, 48, 51, 55, 62, 65, 68, 71, 74]\n",
      "Group 14: [1, 2, 4, 5, 7, 8, 10, 11, 13, 14, 16, 17, 19, 20, 22, 23, 25, 26, 28, 29, 31, 32, 38, 39, 45, 46, 52, 53, 59, 60, 81, 88, 95, 102, 109]\n",
      "Group 15: [80, 87, 94, 101]\n",
      "Group 16: [83, 90, 97, 104, 111]\n",
      "Group 17: [82, 84, 89, 91, 96, 98, 103, 105, 110, 112]\n",
      "Enforcing maximum group size of 16...\n",
      "Group [0, 3, 6, 9, 15, 18, 21, 24, 30, 34, 37, 41, 44, 48, 51, 55, 62, 65, 68, 71, 74] exceeds maximum size of 16. Performing sub-clustering...\n",
      "Splitting into 2 sub-clusters.\n",
      "Group [1, 2, 4, 5, 7, 8, 10, 11, 13, 14, 16, 17, 19, 20, 22, 23, 25, 26, 28, 29, 31, 32, 38, 39, 45, 46, 52, 53, 59, 60, 81, 88, 95, 102, 109] exceeds maximum size of 16. Performing sub-clustering...\n",
      "Splitting into 3 sub-clusters.\n",
      "Sub-group [1, 4, 7, 10, 13, 16, 19, 22, 25, 28, 31, 38, 45, 52, 59, 81, 88, 95, 102, 109] still exceeds maximum size. Recursively splitting...\n",
      "Group [1, 4, 7, 10, 13, 16, 19, 22, 25, 28, 31, 38, 45, 52, 59, 81, 88, 95, 102, 109] exceeds maximum size of 16. Performing sub-clustering...\n",
      "Splitting into 2 sub-clusters.\n",
      "Final number of feature groups: 22\n",
      "Group 0: [66, 69, 72, 75, 78]\n",
      "Group 1: [67, 70, 73, 76, 79]\n",
      "Group 2: [36, 43, 50]\n",
      "Group 3: [56, 63]\n",
      "Group 4: [35, 42, 49]\n",
      "Group 5: [99, 100]\n",
      "Group 6: [106, 107]\n",
      "Group 7: [113, 114]\n",
      "Group 8: [85, 86]\n",
      "Group 9: [92, 93]\n",
      "Group 10: [12, 27, 58, 77, 108]\n",
      "Group 11: [33, 40, 47, 54, 61]\n",
      "Group 12: [57, 64]\n",
      "Group 13: [0, 3, 6, 9, 15, 18, 21, 24, 30, 37, 44, 51, 65, 68, 71, 74]\n",
      "Group 14: [34, 41, 48, 55, 62]\n",
      "Group 15: [1, 4, 7, 10, 13, 16, 19, 22, 25, 28, 31, 38, 45, 52, 59]\n",
      "Group 16: [81, 88, 95, 102, 109]\n",
      "Group 17: [2, 5, 17, 20]\n",
      "Group 18: [8, 11, 14, 23, 26, 29, 32, 39, 46, 53, 60]\n",
      "Group 19: [80, 87, 94, 101]\n",
      "Group 20: [83, 90, 97, 104, 111]\n",
      "Group 21: [82, 84, 89, 91, 96, 98, 103, 105, 110, 112]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
    "from scipy.spatial.distance import squareform\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define Maximum Group Size\n",
    "# Function to determine hyperparameters based on group size\n",
    "def get_hyperparameters(group_size):\n",
    "    \"\"\"\n",
    "    Returns hidden_size and latent_dim based on the size of the feature group.\n",
    "    \"\"\"\n",
    "    if group_size <= 4:\n",
    "        hidden_size = 16\n",
    "        latent_dim = 2\n",
    "    elif 5 <= group_size <= 8:\n",
    "        hidden_size = 32\n",
    "        latent_dim = 4\n",
    "    elif 9 <= group_size:\n",
    "        hidden_size = 64\n",
    "        latent_dim = 8\n",
    "\n",
    "    return hidden_size, latent_dim\n",
    "# Step 1: Compute Correlation Matrix Between Features\n",
    "print(\"Computing correlation matrix...\")\n",
    "corr_matrix = np.corrcoef(train_data, rowvar=False)\n",
    "\n",
    "# Step 2: Convert Correlation to Distance\n",
    "print(\"Converting correlation to distance...\")\n",
    "distance_matrix = 1 - np.abs(corr_matrix)\n",
    "\n",
    "# Step 3: Condense the Distance Matrix\n",
    "print(\"Condensing distance matrix...\")\n",
    "condensed_distance = squareform(distance_matrix, checks=False)\n",
    "\n",
    "# Step 4: Perform Hierarchical Clustering\n",
    "print(\"Performing hierarchical clustering...\")\n",
    "Z = linkage(condensed_distance, method='ward')  # 'ward' linkage is appropriate here\n",
    "\n",
    "# Step 5: Visualize the Dendrogram (Optional)\n",
    "print(\"Plotting dendrogram...\")\n",
    "plt.figure(figsize=(15, 7))\n",
    "dendrogram(Z, labels=range(len(corr_matrix)), leaf_rotation=90)\n",
    "plt.title('Feature Clustering Dendrogram')\n",
    "plt.xlabel('Feature Index')\n",
    "plt.ylabel('Distance')\n",
    "plt.show()\n",
    "\n",
    "# Step 6: Assign Initial Cluster Labels\n",
    "# Decide on a threshold based on dendrogram analysis\n",
    "initial_threshold = 0.6  # Example threshold; adjust based on your dendrogram\n",
    "print(f\"Assigning initial clusters with threshold {initial_threshold}...\")\n",
    "cluster_assignments = fcluster(Z, t=initial_threshold, criterion='distance')\n",
    "\n",
    "# Create initial feature groups based on cluster assignments\n",
    "feature_groups_dict = {}\n",
    "for idx, cluster_id in enumerate(cluster_assignments):\n",
    "    if cluster_id not in feature_groups_dict:\n",
    "        feature_groups_dict[cluster_id] = []\n",
    "    feature_groups_dict[cluster_id].append(idx)\n",
    "\n",
    "feature_groups = [feature_groups_dict[key] for key in sorted(feature_groups_dict.keys())]\n",
    "print(f'Initial number of feature groups: {len(feature_groups)}')\n",
    "for idx, group in enumerate(feature_groups):\n",
    "    print(f'Group {idx}: {group}')\n",
    "\n",
    "# Step 7: Enforce Maximum Group Size with Sub-Clustering\n",
    "from math import ceil\n",
    "\n",
    "def enforce_max_group_size(feature_groups, train_data, max_size, distance_metric='euclidean', linkage_method='ward', sub_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Splits feature groups that exceed the maximum size by performing sub-clustering.\n",
    "    \n",
    "    Parameters:\n",
    "    - feature_groups: List of feature groups (each group is a list of feature indices)\n",
    "    - train_data: Original training data (numpy array)\n",
    "    - max_size: Maximum allowed number of features per group\n",
    "    - distance_metric: Distance metric for sub-clustering\n",
    "    - linkage_method: Linkage method for sub-clustering\n",
    "    - sub_threshold: Distance threshold for sub-clustering\n",
    "    \n",
    "    Returns:\n",
    "    - new_feature_groups: List of feature groups with sizes <= max_size\n",
    "    \"\"\"\n",
    "    new_feature_groups = []\n",
    "    for group in feature_groups:\n",
    "        if len(group) <= max_size:\n",
    "            new_feature_groups.append(group)\n",
    "        else:\n",
    "            print(f\"Group {group} exceeds maximum size of {max_size}. Performing sub-clustering...\")\n",
    "            # Calculate the number of sub-clusters needed\n",
    "            num_subclusters = ceil(len(group) / max_size)\n",
    "            print(f\"Splitting into {num_subclusters} sub-clusters.\")\n",
    "            \n",
    "            # Extract the sub-data for the current group\n",
    "            sub_data = train_data[:, group]\n",
    "            \n",
    "            # Compute correlation distance for the sub-group\n",
    "            sub_corr_matrix = np.corrcoef(sub_data, rowvar=False)\n",
    "            sub_distance_matrix = 1 - np.abs(sub_corr_matrix)\n",
    "            \n",
    "            # Condense the distance matrix\n",
    "            sub_condensed_distance = squareform(sub_distance_matrix, checks=False)\n",
    "            \n",
    "            # Handle cases where all features are identical or highly correlated\n",
    "            if np.all(sub_distance_matrix == 0):\n",
    "                # All features are identical; split into equal-sized groups\n",
    "                split_indices = np.array_split(group, num_subclusters)\n",
    "                for sub_group in split_indices:\n",
    "                    new_feature_groups.append(list(sub_group))\n",
    "                continue\n",
    "            \n",
    "            # Perform hierarchical clustering on the sub-group\n",
    "            Z_sub = linkage(sub_condensed_distance, method=linkage_method)\n",
    "            \n",
    "            # Assign sub-cluster labels based on the required number of sub-clusters\n",
    "            sub_cluster_assignments = fcluster(Z_sub, t=num_subclusters, criterion='maxclust')\n",
    "            \n",
    "            # Create sub-feature groups\n",
    "            sub_feature_groups_dict = {}\n",
    "            for idx_sub, sub_cluster_id in enumerate(sub_cluster_assignments):\n",
    "                if sub_cluster_id not in sub_feature_groups_dict:\n",
    "                    sub_feature_groups_dict[sub_cluster_id] = []\n",
    "                sub_feature_groups_dict[sub_cluster_id].append(group[idx_sub])\n",
    "            \n",
    "            # Append the sub-groups to the new_feature_groups\n",
    "            for sub_group in sub_feature_groups_dict.values():\n",
    "                if len(sub_group) > max_size:\n",
    "                    print(f\"Sub-group {sub_group} still exceeds maximum size. Recursively splitting...\")\n",
    "                    # Recursive call to handle further splitting\n",
    "                    smaller_sub_groups = enforce_max_group_size([sub_group], train_data, max_size, distance_metric, linkage_method, sub_threshold)\n",
    "                    new_feature_groups.extend(smaller_sub_groups)\n",
    "                else:\n",
    "                    new_feature_groups.append(sub_group)\n",
    "    return new_feature_groups\n",
    "\n",
    "# Apply the enforcement of maximum group size\n",
    "print(f\"Enforcing maximum group size of {MAX_GROUP_SIZE}...\")\n",
    "final_feature_groups = enforce_max_group_size(feature_groups, train_data_scaled, MAX_GROUP_SIZE)\n",
    "print(f'Final number of feature groups: {len(final_feature_groups)}')\n",
    "for idx, group in enumerate(final_feature_groups):\n",
    "    print(f'Group {idx}: {group}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing first-layer VAEs, loading them...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Simon Ulloa\\AppData\\Local\\Temp\\ipykernel_33188\\597618704.py:35: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  vae.load_state_dict(torch.load(MODEL_DIR / f'first_layer_vae_{idx}.pth', map_location=DEVICE))\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "# Train First-Layer VAEs\n",
    "############################\n",
    "def all_vae_weights_exist(num_vaes):\n",
    "    for idx in range(num_vaes):\n",
    "        vae_path = MODEL_DIR / f'first_layer_vae_{idx}.pth'\n",
    "        if not vae_path.is_file():\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "first_layer_vaes = []\n",
    "info_dict = {\n",
    "    'feature_groups': final_feature_groups,\n",
    "    'scaler': scaler,\n",
    "    'train_size': TRAIN_SIZE,\n",
    "    'input_dim': data.shape[1],\n",
    "    'first_layer_hyperparameters': [],  # List to store (hidden_size, latent_dim) tuples\n",
    "}\n",
    "\n",
    "if MODEL_DIR.is_dir() and info_path.is_file():\n",
    "    with open(info_path, 'rb') as f:\n",
    "        saved_info = pickle.load(f)\n",
    "    saved_feature_groups = saved_info['feature_groups']\n",
    "    saved_scaler = saved_info['scaler']\n",
    "    saved_hyperparameters = saved_info['first_layer_hyperparameters']\n",
    "    \n",
    "    if all_vae_weights_exist(len(saved_feature_groups)):\n",
    "        print(\"Found existing first-layer VAEs, loading them...\")\n",
    "        for idx, (features, hyperparams) in enumerate(zip(saved_feature_groups, saved_hyperparameters)):\n",
    "            hidden_size, latent_dim = hyperparams\n",
    "            input_dim = len(features)\n",
    "            vae = VAE(input_dim, hidden_size, latent_dim).to(DEVICE)\n",
    "            vae.load_state_dict(torch.load(MODEL_DIR / f'first_layer_vae_{idx}.pth', map_location=DEVICE))\n",
    "            vae.eval()\n",
    "            first_layer_vaes.append(vae)\n",
    "        feature_groups = saved_feature_groups\n",
    "        scaler = saved_scaler\n",
    "    else:\n",
    "        print(\"VAE weights are missing. Retraining first-layer VAEs...\")\n",
    "        # Retrain first-layer VAEs\n",
    "        first_layer_vaes = []\n",
    "        info_dict['first_layer_hyperparameters'] = []\n",
    "        for idx, features in enumerate(saved_feature_groups):\n",
    "            input_dim = len(features)\n",
    "            hidden_size, latent_dim = get_hyperparameters(input_dim)\n",
    "            vae = VAE(input_dim, hidden_size, latent_dim).to(DEVICE)\n",
    "            optimizer = torch.optim.Adam(vae.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "            train_dataset = FirstLayerDataset(train_data_scaled, features)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    \n",
    "            vae.train()\n",
    "            for epoch in range(EPOCHS_FIRST_LAYER):\n",
    "                total_loss = 0\n",
    "                for batch in train_loader:\n",
    "                    batch = batch.to(DEVICE)\n",
    "                    optimizer.zero_grad()\n",
    "                    recon_x, mu, logvar = vae(batch)\n",
    "                    loss = vae_loss(recon_x, batch, mu, logvar)\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(vae.parameters(), MAX_GRAD_NORM)\n",
    "                    optimizer.step()\n",
    "                    total_loss += loss.item()\n",
    "                avg_loss = total_loss / len(train_loader.dataset)\n",
    "                print(f'First Layer VAE {idx+1}/{len(saved_feature_groups)} Epoch [{epoch+1}/{EPOCHS_FIRST_LAYER}] Loss: {avg_loss:.4f}')\n",
    "    \n",
    "            vae.eval()\n",
    "            first_layer_vaes.append(vae)\n",
    "            hidden_size, latent_dim = get_hyperparameters(input_dim)\n",
    "            info_dict['first_layer_hyperparameters'].append((hidden_size, latent_dim))\n",
    "    \n",
    "            # Save the trained VAE\n",
    "            vae_path = MODEL_DIR / f'first_layer_vae_{idx}.pth'\n",
    "            torch.save(vae.state_dict(), vae_path)\n",
    "            print(f\"Saved {vae_path}\")\n",
    "    \n",
    "        # Save the updated info_dict\n",
    "        with open(info_path, 'wb') as f:\n",
    "            pickle.dump(info_dict, f)\n",
    "        print(\"Saved feature groups, scaler, and configuration info.\")\n",
    "else:\n",
    "    # No existing model or info, train from scratch\n",
    "    print(\"No existing models found, training first-layer VAEs...\")\n",
    "    first_layer_vaes = []\n",
    "    info_dict['first_layer_hyperparameters'] = []\n",
    "    \n",
    "    for idx, features in enumerate(final_feature_groups):\n",
    "        input_dim = len(features)\n",
    "        hidden_size, latent_dim = get_hyperparameters(input_dim)\n",
    "        vae = VAE(input_dim, hidden_size, latent_dim).to(DEVICE)\n",
    "        optimizer = torch.optim.Adam(vae.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "        train_dataset = FirstLayerDataset(train_data_scaled, features)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    \n",
    "        vae.train()\n",
    "        for epoch in range(EPOCHS_FIRST_LAYER):\n",
    "            total_loss = 0\n",
    "            for batch in train_loader:\n",
    "                batch = batch.to(DEVICE)\n",
    "                optimizer.zero_grad()\n",
    "                recon_x, mu, logvar = vae(batch)\n",
    "                loss = vae_loss(recon_x, batch, mu, logvar)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(vae.parameters(), MAX_GRAD_NORM)\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "            avg_loss = total_loss / len(train_loader.dataset)\n",
    "            print(f'First Layer VAE {idx+1}/{len(final_feature_groups)} Epoch [{epoch+1}/{EPOCHS_FIRST_LAYER}] Loss: {avg_loss:.4f}')\n",
    "    \n",
    "        vae.eval()\n",
    "        first_layer_vaes.append(vae)\n",
    "        hidden_size, latent_dim = get_hyperparameters(input_dim)\n",
    "        info_dict['first_layer_hyperparameters'].append((hidden_size, latent_dim))\n",
    "    \n",
    "        # Save the trained VAE\n",
    "        vae_path = MODEL_DIR / f'first_layer_vae_{idx}.pth'\n",
    "        torch.save(vae.state_dict(), vae_path)\n",
    "        print(f\"Saved {vae_path}\")\n",
    "    \n",
    "    # Save the updated info_dict\n",
    "    with open(info_path, 'wb') as f:\n",
    "        pickle.dump(info_dict, f)\n",
    "    print(\"Saved feature groups, scaler, and configuration info.\")\n",
    "# first_layer_vaes now loaded or trained and ready for next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model_weights_2\\train_subspace_errors.npy, loading subspace errors...\n",
      "Initializing SecondLayerDataset...\n",
      "Dataset initialized with 1000000 samples.\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "# Compute Training Error Vectors for Second-Layer Input (Batch Processing)\n",
    "############################\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "\n",
    "\n",
    "def process_sample_errors(sample, vaes, groups, device):\n",
    "    start_time = time.time()\n",
    "    sample_errors = []\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            for vae, features in zip(vaes, groups):\n",
    "                x_sub = torch.tensor(sample[features], dtype=torch.float32, device=device).unsqueeze(0)\n",
    "                recon_x, mu, logvar = vae(x_sub)\n",
    "                mse_error = nn.functional.mse_loss(recon_x, x_sub, reduction='mean').item()\n",
    "                sample_errors.append(mse_error)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    finally:\n",
    "        print(f\"Sample processed in {time.time() - start_time:.4f} seconds\")\n",
    "    return sample_errors\n",
    "\n",
    "def compute_subspace_errors(data, vaes, groups, device=DEVICE, max_workers=WORKER_NODES):\n",
    "    errors = [None] * len(data)\n",
    "    completed = 0\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {\n",
    "            executor.submit(process_sample_errors, data[i], vaes, groups, device): i\n",
    "            for i in range(len(data))\n",
    "        }\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            i = futures[future]\n",
    "            errors[i] = future.result()\n",
    "            completed += 1\n",
    "            tqdm.write(f\"Completed {completed}/{len(data)} samples\")\n",
    "\n",
    "    return np.array(errors)\n",
    "\n",
    "\n",
    "train_errors_path = MODEL_DIR / 'train_subspace_errors.npy'\n",
    "if train_errors_path.is_file():\n",
    "    print(f\"Found {train_errors_path}, loading subspace errors...\")\n",
    "    train_subspace_errors = np.load(train_errors_path)\n",
    "else:\n",
    "    print(\"Computing subspace errors for training data (multithreaded)...\")\n",
    "    train_subspace_errors = compute_subspace_errors(train_data, first_layer_vaes, feature_groups, device=DEVICE, max_workers=WORKER_NODES)\n",
    "    np.save(train_errors_path, train_subspace_errors)\n",
    "    print(f\"Saved subspace errors to {train_errors_path}\")\n",
    "\n",
    "# Normalize errors for second-layer training\n",
    "min_errors = train_subspace_errors.min(axis=0)\n",
    "max_errors = train_subspace_errors.max(axis=0)\n",
    "\n",
    "# Avoid division by zero if max == min\n",
    "max_errors = np.where(max_errors == min_errors, min_errors+1e-6, max_errors)\n",
    "\n",
    "train_normalized_errors = (train_subspace_errors - min_errors) / (max_errors - min_errors)\n",
    "\n",
    "second_layer_input_dim = train_normalized_errors.shape[1]\n",
    "\n",
    "second_dataset = SecondLayerDataset(train_normalized_errors)\n",
    "second_loader = DataLoader(second_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 shape: torch.Size([1024, 22])\n",
      "Batch 2 shape: torch.Size([1024, 22])\n",
      "Batch 3 shape: torch.Size([1024, 22])\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    for i, batch in enumerate(second_loader):\n",
    "        print(f\"Batch {i+1} shape: {batch.shape}\")\n",
    "        if i >= 2:  # Check first 3 batches\n",
    "            break\n",
    "except Exception as e:\n",
    "    print(f\"DataLoader encountered an error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/8: 100%|| 977/977 [00:07<00:00, 130.74batch/s, loss=0.0437]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second Layer Epoch [1/8] Average Loss: 0.1362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/8: 100%|| 977/977 [00:07<00:00, 129.20batch/s, loss=0.0310]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second Layer Epoch [2/8] Average Loss: 0.0369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/8: 100%|| 977/977 [00:07<00:00, 132.19batch/s, loss=0.0262]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second Layer Epoch [3/8] Average Loss: 0.0281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/8: 100%|| 977/977 [00:07<00:00, 128.59batch/s, loss=0.0211]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second Layer Epoch [4/8] Average Loss: 0.0238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/8: 100%|| 977/977 [00:07<00:00, 130.28batch/s, loss=0.0203]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second Layer Epoch [5/8] Average Loss: 0.0216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/8: 100%|| 977/977 [00:07<00:00, 132.40batch/s, loss=0.0199]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second Layer Epoch [6/8] Average Loss: 0.0206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/8: 100%|| 977/977 [00:07<00:00, 129.00batch/s, loss=0.0202]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second Layer Epoch [7/8] Average Loss: 0.0201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/8: 100%|| 977/977 [00:07<00:00, 128.05batch/s, loss=0.0200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second Layer Epoch [8/8] Average Loss: 0.0198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (fc1): Linear(in_features=22, out_features=128, bias=True)\n",
       "  (fc_mu): Linear(in_features=128, out_features=32, bias=True)\n",
       "  (fc_logvar): Linear(in_features=128, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=22, bias=True)\n",
       "  (activation): LeakyReLU(negative_slope=0.2)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################\n",
    "# Train Second-Layer VAE on Normalized Error Vectors with Progress Feedback\n",
    "############################\n",
    "second_layer_vae = VAE(second_layer_input_dim, SECOND_LAYER_HIDDEN_SIZE, LATENT_DIM_SECOND_LAYER).to(DEVICE)\n",
    "second_optimizer = torch.optim.Adam(second_layer_vae.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "second_layer_vae.train()\n",
    "for epoch in range(EPOCHS_SECOND_LAYER):\n",
    "    total_loss = 0\n",
    "    # Initialize tqdm progress bar for batches within the current epoch\n",
    "    batch_iterator = tqdm(second_loader, desc=f'Epoch {epoch+1}/{EPOCHS_SECOND_LAYER}', unit='batch')\n",
    "    \n",
    "    for i, batch in enumerate(batch_iterator):\n",
    "        batch = batch.to(DEVICE)\n",
    "        second_optimizer.zero_grad()\n",
    "        recon_x, mu, logvar = second_layer_vae(batch)\n",
    "        loss = vae_loss(recon_x, batch, mu, logvar)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(second_layer_vae.parameters(), MAX_GRAD_NORM)\n",
    "        second_optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Update the progress bar with the current batch loss\n",
    "        batch_iterator.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "    \n",
    "    # Calculate the average loss for the epoch\n",
    "    avg_loss = total_loss / len(second_loader)\n",
    "    print(f'Second Layer Epoch [{epoch+1}/{EPOCHS_SECOND_LAYER}] Average Loss: {avg_loss:.4f}')\n",
    "\n",
    "second_layer_vae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "############################\n",
    "# Anomaly Scoring on Test Data\n",
    "############################\n",
    "# Define a dataset for test data\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# Modify get_test_subspace_errors to use batching\n",
    "def get_test_subspace_errors(data, vaes, groups, min_err, max_err, batch_size=1024, num_workers=0):\n",
    "    errors = []\n",
    "    test_dataset = TestDataset(data)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    \n",
    "    total_batches = len(test_loader)\n",
    "    for batch_idx, batch_samples in enumerate(test_loader):\n",
    "        # Print progress every 10 batches\n",
    "        if batch_idx % 10 == 0 or batch_idx == total_batches - 1:\n",
    "            print(f\"Processing batch {batch_idx + 1}/{total_batches}\")\n",
    "        \n",
    "        batch_errors = []\n",
    "        with torch.no_grad():\n",
    "            for vae, features in zip(vaes, groups):\n",
    "                x_sub = torch.tensor(batch_samples[:, features], dtype=torch.float32, device=DEVICE)\n",
    "                recon_x, mu, logvar = vae(x_sub)\n",
    "                mse_error = nn.functional.mse_loss(recon_x, x_sub, reduction='none').mean(dim=1)\n",
    "                batch_errors.append(mse_error.cpu().numpy())\n",
    "        batch_errors = np.stack(batch_errors, axis=1)\n",
    "        errors.append(batch_errors)\n",
    "    \n",
    "    errors = np.concatenate(errors, axis=0)\n",
    "    errors = (errors - min_err) / (max_err - min_err)\n",
    "    errors = np.clip(errors, 0, 1)\n",
    "    return errors\n",
    "\n",
    "def compute_final_anomaly_scores(test_subspace_errors, second_layer_vae, batch_size=1024, num_workers=0):\n",
    "    test_dataset = TestDataset(test_subspace_errors)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    \n",
    "    total_batches = len(test_loader)\n",
    "    test_scores = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, error_vec_batch in enumerate(test_loader):\n",
    "            # Print progress every 10 batches\n",
    "            if batch_idx % 10 == 0 or batch_idx == total_batches - 1:\n",
    "                print(f\"Scoring batch {batch_idx + 1}/{total_batches}\")\n",
    "            \n",
    "            error_vec_batch = torch.tensor(error_vec_batch, dtype=torch.float32, device=DEVICE)\n",
    "            recon_x, mu, logvar = second_layer_vae(error_vec_batch)\n",
    "            mse_error = nn.functional.mse_loss(recon_x, error_vec_batch, reduction='none').mean(dim=1)\n",
    "            test_scores.extend(mse_error.cpu().numpy())\n",
    "    return np.array(test_scores)\n",
    "\n",
    "# Use the modified functions\n",
    "test_errors_path = MODEL_DIR / 'test_subspace_errors.npy'\n",
    "if test_errors_path.is_file():\n",
    "    print(f\"Found {test_errors_path}, loading test subspace errors...\")\n",
    "    test_subspace_errors = np.load(test_errors_path)\n",
    "else:\n",
    "    test_subspace_errors = get_test_subspace_errors(test_data, first_layer_vaes, feature_groups, min_errors, max_errors)\n",
    "    np.save(test_errors_path, test_subspace_errors)\n",
    "    print(f\"Saved test subspace errors to {test_errors_path}\")\n",
    "\n",
    "test_scores_path = MODEL_DIR / 'test_results.csv'\n",
    "if test_scores_path.is_file():\n",
    "    print(f\"Found {test_scores_path}, loading test_scores from disk...\")\n",
    "    test_scores = np.loadtxt(test_scores_path, delimiter=',')\n",
    "else:\n",
    "    print(\"Computing final anomaly scores from second-layer VAE...\")\n",
    "    test_scores = compute_final_anomaly_scores(test_subspace_errors, second_layer_vae)\n",
    "    np.savetxt(test_scores_path, test_scores, delimiter=',')\n",
    "    print(f\"Test scores saved to {test_scores_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "# Visualization and Metric Computation\n",
    "############################\n",
    "normal_scores = test_scores[test_labels == 0]\n",
    "malicious_scores = test_scores[test_labels == 1]\n",
    "\n",
    "# Plot Histograms\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(normal_scores, bins=100, color='blue', alpha=0.5, label='Normal', kde=True)\n",
    "sns.histplot(malicious_scores, bins=100, color='red', alpha=0.5, label='Malicious', kde=True)\n",
    "plt.axvline(x=ANOMALY_THRESHOLD, color='green', linestyle='--', label=f'Threshold: {ANOMALY_THRESHOLD:.4f}')\n",
    "plt.xlabel('Anomaly Score')\n",
    "plt.ylabel('Number of Packets')\n",
    "plt.title('Distribution of Anomaly Scores for Test Packets')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(distribution_png_path)\n",
    "plt.close()\n",
    "print(f\"Anomaly score distribution plot saved to '{distribution_png_path}'\")\n",
    "\n",
    "df_scores = pd.DataFrame({\n",
    "    'Anomaly Score': test_scores,\n",
    "    'Label': ['Normal' if label == 0 else 'Malicious' for label in test_labels]\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.boxplot(x='Label', y='Anomaly Score', data=df_scores, palette={'Normal': 'blue', 'Malicious': 'red'})\n",
    "plt.title('Boxplot of Anomaly Scores by Label')\n",
    "plt.tight_layout()\n",
    "plt.savefig(boxplot_png_path)\n",
    "plt.close()\n",
    "print(f\"Anomaly score boxplot saved to '{boxplot_png_path}'\")\n",
    "\n",
    "if not os.path.exists(txt_path) and not os.path.exists(png_path):\n",
    "    print(\"Computing metrics and generating plot since neither test_results.txt nor result.png exist...\")\n",
    "    \n",
    "    # Find best threshold via F1-score on test set\n",
    "    thresholds = np.linspace(np.min(test_scores), np.max(test_scores), num=1000)\n",
    "    best_f1 = -1\n",
    "    best_threshold = ANOMALY_THRESHOLD\n",
    "\n",
    "    # for threshold in thresholds:\n",
    "    #     y_pred = (test_scores >= threshold).astype(int)\n",
    "    #     f1_val = f1_score(test_labels, y_pred, zero_division=0)\n",
    "    #     if f1_val > best_f1:\n",
    "    #         best_f1 = f1_val\n",
    "    #         best_threshold = threshold\n",
    "\n",
    "    ANOMALY_THRESHOLD = 0.15\n",
    "    print(f\"Optimal Anomaly Threshold based on F1-score: {ANOMALY_THRESHOLD:.4f}\")\n",
    "    print(f\"Best F1-score: {best_f1:.4f}\")\n",
    "\n",
    "    y_pred = (test_scores >= ANOMALY_THRESHOLD).astype(int)\n",
    "\n",
    "    acc = accuracy_score(test_labels, y_pred)\n",
    "    prec = precision_score(test_labels, y_pred, zero_division=0)\n",
    "    rec = recall_score(test_labels, y_pred, zero_division=0)\n",
    "    f1 = f1_score(test_labels, y_pred, zero_division=0)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(test_labels, y_pred).ravel()\n",
    "    tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    fnr = fn / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "    with open(txt_path, 'w') as f:\n",
    "        f.write(\"Model Parameters:\\n\")\n",
    "        f.write(f\"FIRST_LAYER_HIDDEN_SIZE: {FIRST_LAYER_HIDDEN_SIZE}\\n\")\n",
    "        f.write(f\"SECOND_LAYER_HIDDEN_SIZE: {SECOND_LAYER_HIDDEN_SIZE}\\n\")\n",
    "        f.write(f\"LATENT_DIM_FIRST_LAYER: {LATENT_DIM_FIRST_LAYER}\\n\")\n",
    "        f.write(f\"LATENT_DIM_SECOND_LAYER: {LATENT_DIM_SECOND_LAYER}\\n\")\n",
    "        f.write(f\"CLUSTER_THRESHOLD: {CLUSTER_THRESHOLD}\\n\")\n",
    "        f.write(f\"BATCH_SIZE: {BATCH_SIZE}\\n\")\n",
    "        f.write(f\"EPOCHS_FIRST_LAYER: {EPOCHS_FIRST_LAYER}\\n\")\n",
    "        f.write(f\"EPOCHS_SECOND_LAYER: {EPOCHS_SECOND_LAYER}\\n\")\n",
    "        f.write(f\"LEARNING_RATE: {LEARNING_RATE}\\n\")\n",
    "        f.write(f\"MAX_GRAD_NORM: {MAX_GRAD_NORM}\\n\")\n",
    "        f.write(f\"CLAMP_LOGVAR_LOW: {CLAMP_LOGVAR_LOW}\\n\")\n",
    "        f.write(f\"CLAMP_LOGVAR_HIGH: {CLAMP_LOGVAR_HIGH}\\n\")\n",
    "        f.write(\"\\nMetrics:\\n\")\n",
    "        f.write(f\"Anomaly Threshold: {ANOMALY_THRESHOLD}\\n\")\n",
    "        f.write(f\"Number of Test Packets: {len(test_labels)}\\n\")\n",
    "        f.write(f\"Accuracy: {acc:.4f}\\n\")\n",
    "        f.write(f\"Precision: {prec:.4f}\\n\")\n",
    "        f.write(f\"Recall: {rec:.4f}\\n\")\n",
    "        f.write(f\"F1-score: {f1:.4f}\\n\")\n",
    "        f.write(f\"True Positive Rate (TPR): {tpr:.4f}\\n\")\n",
    "        f.write(f\"False Negative Rate (FNR): {fnr:.4f}\\n\")\n",
    "    print(f\"Metrics saved to '{txt_path}'\")\n",
    "\n",
    "    # Plot final results with updated threshold\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.scatter(np.arange(len(test_scores))[test_labels==0], test_scores[test_labels==0], s=1, c='blue', label='Normal')\n",
    "    plt.scatter(np.arange(len(test_scores))[test_labels==1], test_scores[test_labels==1], s=1, c='red', label='Malicious')\n",
    "    plt.axhline(y=ANOMALY_THRESHOLD, color='green', linestyle='--', label=f'Threshold: {ANOMALY_THRESHOLD:.4f}')\n",
    "    plt.xlabel('Packet Index (Test Set)')\n",
    "    plt.ylabel('Anomaly Score')\n",
    "    plt.title('Anomaly Scores on Test Packets')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(png_path)\n",
    "    plt.close()\n",
    "    print(f\"Plot saved to '{png_path}'\")\n",
    "\n",
    "    # Precision-Recall Curve\n",
    "    precision_vals, recall_vals, pr_thresholds = precision_recall_curve(test_labels, test_scores)\n",
    "    f1_vals = 2 * (precision_vals * recall_vals) / (precision_vals + recall_vals + 1e-8)\n",
    "    best_pr_idx = np.argmax(f1_vals)\n",
    "    best_pr_threshold = pr_thresholds[best_pr_idx]\n",
    "    best_pr_f1 = f1_vals[best_pr_idx]\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(recall_vals, precision_vals, marker='.', label='Precision-Recall Curve')\n",
    "    plt.scatter(recall_vals[best_pr_idx], precision_vals[best_pr_idx], color='red',\n",
    "                label=f'Best Threshold: {best_pr_threshold:.4f}\\nF1-score: {best_pr_f1:.4f}')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(precision_recall_png_path)\n",
    "    plt.close()\n",
    "    print(f\"Precision-Recall curve saved to '{precision_recall_png_path}'\")\n",
    "\n",
    "    # ROC Curve\n",
    "    fpr_vals, tpr_vals, roc_thresholds = roc_curve(test_labels, test_scores)\n",
    "    roc_auc = roc_auc_score(test_labels, test_scores)\n",
    "    distances = np.sqrt((1 - tpr_vals)**2 + fpr_vals**2)\n",
    "    best_roc_idx = np.argmin(distances)\n",
    "    best_roc_threshold = roc_thresholds[best_roc_idx]\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(fpr_vals, tpr_vals, label=f'ROC Curve (AUC = {roc_auc:.4f})')\n",
    "    plt.scatter(fpr_vals[best_roc_idx], tpr_vals[best_roc_idx], color='red',\n",
    "                label=f'Best Threshold: {best_roc_threshold:.4f}')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "    plt.xlabel('False Positive Rate (FPR)')\n",
    "    plt.ylabel('True Positive Rate (TPR)')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(roc_curve_png_path)\n",
    "    plt.close()\n",
    "    print(f\"ROC curve saved to '{roc_curve_png_path}'\")\n",
    "\n",
    "    # PCA Plot on error vectors (Optional)\n",
    "    # Already computed: we have train_normalized_errors as input\n",
    "    # If you want, visualize train_normalized_errors with PCA or test data error distributions\n",
    "\n",
    "else:\n",
    "    print(\"Not updating metrics or plot because test_results.txt or result.png (or both) already exist.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
